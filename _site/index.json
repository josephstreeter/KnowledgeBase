{
  "docs/RTL-SDR/index.html": {
    "href": "docs/RTL-SDR/index.html",
    "title": "Software Defined Radio | Crusader Two One",
    "keywords": "Software Defined Radio Software Defined Radio using RTL-SDR dongle on Ubuntu Linux More information RRL-SDR A package for Ubuntu: [https://launchpad.net/ubuntu/bionic/+...] sudo apt install -y rtl-sdr sudo apt install -y sox sudo apt install -y multimon-ng RTL_FM A cli demodulation tool: http://kmkeen.com/rtl-demod-guide/ http://main.lv/writeup/rtlsdr_usage.md Tune in FM Broadcast rtl_fm -M wbfm -f 89.1M | play -r 32k -t raw -e s -b 16 -c 1 -V1 - '-f ...' indicated the frequency to tune to -M fm means narrowband FM -s 170k means to sample the radio at 170k/sec -A fast uses a fast polynominal approximation of arctangent -r 32k means to lowpass/resample at 32kHz -l 0 disables squelch -E deemp applies a deemphesis filter Police Scanner rtl_fm -M fm -f 154.42M -f 154.75M -f 154.82M -f 154.89M -s 12k -g 50 -l 70 | play -r 12k ... -M fm narrowband FM -f ... frequency to tune, use multiple times for scanning -s 12k sample rate, about as narrow as possible for FM voice -g 50 set gain to maximum (use a value appropriate to your dongle) -l 70 set squelch to 70. The exact values varies a lot. Changing the gain or sample rate will require a change in the squelch to compensate. Scan Airband rtl_fm -M am -f 118M:137M:25k -s 12k -g 50 -l 280 | play -r 12k ... -M am AM demodulation -f start:stop:interval a range of frequencies to scan -s 12k same as above -g 50 same as above -l 280 squelch level, exact value varies a lot Pager Decoder rtl_fm -M fm -f 929.77M -s 22050 -g 10 -l 250 | multimon -t raw /dev/stdin Scan for signals rtl_power -f 76M:108M:125k -i 1 fm_stations.csv GQRX graphical spectrum analyzer: http://http://gqrx.dk To install: sudo apt-get install gqrx-sdr ACARS DECODER A realtime aircraft message decoding: https://github.com/TLeconte/acarsdec Check ACARS frequency here: https://www.acarsd.org/ACARS_frequencies.html DUMP1090 ADS-B airplane messages DECODER: https://github.com/antirez/dump1090 / https://www.ads-binfo.com/ RTL_433 Decoding Low Power devices on unlicensed bands 433MHz/315 MHz/ 868MHz / 915MHz - like keyfobs, meteo/weather stations, sensors sniffer: https://github.com/merbanan/rtl_433 sudo apt-get install rtl-433 MULTIMON-NG A multi system DECODER: https://github.com/EliasOenal/multimon-ng APRS (Automatic Packet Reporting System) decoding video using MULTIMON-NG here https://www.youtube.com/watch?v=Cfnrr... CAPTURING & DECODING SATELLITES with NOAA-APT with simple dipole antenna - see my other video here : https://www.youtube.com/watch?v=Fk0WU... UBUNTU 18.04 and RTL-SDR Dongle Setup RTLSDR installation on Ubuntu: Check if USB RTLSDR is detected and what are Product_ID and Vendor_ID (f.ex. idVendor=0bda, idProduct=2832 ) lsusb Bus 002 Device 001: ID 1d6b:0003 Linux Foundation 3.0 root hub Bus 001 Device 005: ID 8087:0a2b Intel Corp. Bluetooth wireless interface Bus 001 Device 004: ID 18f8:0f99 [Maxxter] Optical gaming mouse Bus 001 Device 003: ID 413c:2003 Dell Computer Corp. Keyboard SK-8115 Bus 001 Device 008: ID 0bda:2838 Realtek Semiconductor Corp. RTL2838 DVB-T <--- Bus 001 Device 001: ID 1d6b:0002 Linux Foundation 2.0 root hub Blacklist ordinary DVB-T drivers in Linux Kernel not to interfere with rtlsdr library vi /etc/modprobe.d/blacklist.conf add in this file following lines (add line respectively to ProductID value) : blacklist dvb_usb_rtl28xxu blacklist rtl2832 blacklist rtl2830 Restart Computer Install the RTL-SDR package: https://launchpad.net/ubuntu/bionic/+... sudo apt-get install rtl-sdr"
  },
  "docs/ansible/index.html": {
    "href": "docs/ansible/index.html",
    "title": "Ansible | Crusader Two One",
    "keywords": "Ansible Ansible Setup Install Ansible apt update && apt upgrade -y apt install ansible -y Create directory to store ansible related files Ansible Sample Setup sudo mkdir /etc/ansible Populate Inventory Enter hosts by role in an inventory file. The file can be an INI or YAML. YAML: mail.example.com [webservers] foo.example.com bar.example.com [dbservers] one.example.com two.example.com three.example.com INI: mail.example.com [webservers] foo.example.com bar.example.com [dbservers] one.example.com two.example.com three.example.com Create Playbook Create a playbook. Configure Remote Hosts Linux Hosts Create user account sudo useradd -m ansi sudo password ansi Copy SSH Key ssh-copy-id ~/.ssh/<key> ansi@<host>"
  },
  "docs/docfx/index.html": {
    "href": "docs/docfx/index.html",
    "title": "DocFx | Crusader Two One",
    "keywords": "DocFx Quick Start Build your technical documentation site with docfx. Converts .NET assembly, XML code comment, REST API Swagger files and markdown into rendered HTML pages, JSON model or PDF files. Create a New Website In this section we will build a simple documentation site on your local machine. Prerequisites Familiarity with the command line Install .NET SDK 6.0 or higher Make sure you have .NET SDK installed, then open a terminal and enter the following command to install the latest docfx: dotnet tool update -g docfx To create a new docset, run: docfx init This command walks you through creating a new docfx project under the current working directory. To build the docset, run: docfx docfx.json --serve Now you can preview the website on http://localhost:8080. To preview your local changes, save changes then run this command in a new terminal to rebuild the website: docfx docfx.json Publish to GitHub Pages Docfx produces static HTML files under the _site folder ready for publishing to any static site hosting servers. To publish to GitHub Pages: Enable GitHub Pages. Upload _site folder to GitHub Pages using GitHub actions. This is an example GitHub action file that publishes documents to the gh-pages branch: # Your GitHub workflow file under .github/workflows/ # Trigger the action on push to main on: push: branches: - main # Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages permissions: actions: read pages: write id-token: write # Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued. # However, do NOT cancel in-progress runs as we want to allow these production deployments to complete. concurrency: group: \"pages\" cancel-in-progress: false jobs: publish-docs: environment: name: github-pages url: ${{ steps.deployment.outputs.page_url }} runs-on: ubuntu-latest steps: - name: Checkout uses: actions/checkout@v3 - name: Dotnet Setup uses: actions/setup-dotnet@v3 with: dotnet-version: 8.x - run: dotnet tool update -g docfx - run: docfx <docfx-project-path>/docfx.json - name: Upload artifact uses: actions/upload-pages-artifact@v3 with: # Upload entire repository path: '<docfx-project-path>/_site' - name: Deploy to GitHub Pages id: deployment uses: actions/deploy-pages@v4 Table of Contents A table of contents (TOC) defines the structure of a set of documents. YAML TOC To add a TOC, create a file named toc.yml in the root of the 'doc' directory. Here's the structure for a simple YAML TOC: items: - name: Subject Name items: - href: install.md - href: configure.md - href: useage.md - href: troubleshooting.md TOC node YAML properties: name: An optional display name for the TOC node. When not specified, uses the title metadata or the first Heading 1 element from the referenced article as the display name. href: The path the TOC node leads to. Optional because a node can exist just to parent other nodes. items: If a node has children, they're listed in the items array. uid: The uid of the article. Can be used instead of href. expanded: Expand children on load, only works if the template is modern. When an article is referenced by a TOC through href, the corresponding TOC appears when viewing that article. If multiple TOCs reference the same article, or the article isn't referenced by any TOC, the nearest TOC with the least amount of directory jumps is picked. The order property can customize this pick logic, TOCs with a smaller order value are picked first. The default order is 0. order: 100 items: - ... Nested TOCs To nest a TOC within another TOC, set the href property to point to the toc.yml file that you want to nest. You can also use this structure as a way to reuse a TOC structure in one or more TOC files. Consider the following two toc.yml files: toc.yml: items: - name: Overview href: overview.md - name: Reference href: api/toc.yml api/toc.yml: items: - name: System.String href: system.string.yml - name: System.Float href: system.float.yml This structure renders as follows: Overview Reference ├─ System.String ├─ System.Float Nested TOCs by default have order set to 100 to let containing TOCs take precedence. Reference TOCs To reference another TOC without embeding it to a parent TOC using nested TOCs, set the href property to point to the directory that you want to reference and end the string with /, this will generate a link pointing to the first article in the referenced TOC. Consider the following folder structure: toc.yml ├─ System ├─ toc.yml ├─ System.Collections ├─ toc.yml toc.yml: - name: System href: System/ - name: System.Collections href: System.Collections/ This structure renders as follows: System # Link to the first article in System/toc.yml System.Collections # Link to the first article in System.Collections/toc.yml Navigation Bar The toc.yml file in the docfx.json folder will be used to fill the content of the navigation bar at the top of the page. It usually uses Reference TOCs to navigate to child pages. The following example creates a navigation bar with two Docs and API entries: toc.yml ├─ docs ├─ toc.yml ├─ api ├─ toc.yml toc.yml: - name: Docs href: docs/ - name: API href: api/ Customize the Site Change Site Icon: -- insert text -- References Write Articles Organize Contents Configure Website Add .NET API Docs"
  },
  "docs/docker/dockercompose.html": {
    "href": "docs/docker/dockercompose.html",
    "title": "Docker Compose | Crusader Two One",
    "keywords": "Docker Compose Tip Pin images to a tag in the docker compose file. This prevents surprise failures due to updates. When new versions are available, update the docker-compose file and use the process below to update containers Update All Containers The following commands with the existing Docker-Compose file will update all of the containers. docker-compose pull docker-compose up --force-recreate --build -d docker image prune -f"
  },
  "docs/docker/index.html": {
    "href": "docs/docker/index.html",
    "title": "Docker | Crusader Two One",
    "keywords": "Docker"
  },
  "docs/docker/install.html": {
    "href": "docs/docker/install.html",
    "title": "Docker Install | Crusader Two One",
    "keywords": "Docker Install Linux Windows Mac OS Ubuntu The following command will install Docker on Ubuntu. sudo apt-get install \\ apt-transport-https \\ ca-certificates \\ curl \\ gnupg-agent \\ software-properties-common curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo apt-key add - sudo add-apt-repository \\ \"deb [arch=amd64] https://download.docker.com/linux/ubuntu \\ $(lsb_release -cs) \\ stable\" sudo apt-get update sudo apt-get install docker-ce docker-ce-cli containerd.io Windows Mac OS"
  },
  "docs/getting-started.html": {
    "href": "docs/getting-started.html",
    "title": "Getting Started | Crusader Two One",
    "keywords": "Getting Started"
  },
  "docs/git/branching.html": {
    "href": "docs/git/branching.html",
    "title": "Branches | Crusader Two One",
    "keywords": "Branches git branch git branch --column git config --global column.ui auto git config --global branch.sort -committerdate"
  },
  "docs/git/configuration.html": {
    "href": "docs/git/configuration.html",
    "title": "Configuration | Crusader Two One",
    "keywords": "Configuration Every time a git is used for the first time, two basic configurations must bet set. Git must be told the name and the email address of the user that is using Git. This information will be used to identity a user's actions. git config --global user.name First I Last git config --global user.email first.last@gmail.com When creating a new branch from the CLI, you may see the following message: $ git init hint: Using 'master' as the name for the initial branch. This default branch name hint: is subject to change. To configure the initial branch name to use in all hint: of your new repositories, which will suppress this warning, call: hint: hint: git config --global init.defaultBranch <name> hint: hint: Names commonly chosen instead of 'master' are 'main', 'trunk' and hint: 'development'. The just-created branch can be renamed via this command: hint: hint: git branch -m <name> Initialized empty Git repository in /home/hades/Documents/repos/AzureTerraform/.git/ $ git config --global intit.defaultBranch main Conditional Configs Separate config for git based on where the files are located. # Configuration for \"work\" projects [include “gitdir:~/projects/work/”] path = ~/projects/work/.gitconfig # Configuration for \"personal\" projects [include “gitdir:~/projects/personal/”] path = ~/projects/personal/.gitconfig Below are the contents of the two config files specified above. # Contents of \"work\" configuration file cat ./work/.gitconfig [user] Email = first.last@work.com [commit] gpgsign = true # Contents of \"personal\" configuration file cat ./personal/.gitconfig [user] Email = first.last@gmail.com [commit] gpgsign = false"
  },
  "docs/git/index.html": {
    "href": "docs/git/index.html",
    "title": "Git | Crusader Two One",
    "keywords": "Git Concept Below is simplified example of a workflow. A working tree is created by initializing a directory (git init) or by cloing an exiting repository (git clone \"path/to/repository\"). Work is then done with the files in the working tree to create a feature or resolve a bug. At a signigicant point in the work, add your changes to the index (git add \"file name\"). Once all of the changes to create the feature or resolve the bug added to the index, the changes are commited to the repository (git commit -m \"commit message\"). flowchart LR A(git) -->|make changes| B(git add) -->|make changes| C(git add) -->|resolved bug| F[git commit] Workflow Generally, the workflow follows the following steps: Get the latest copy of main/master git pull Create an issue/feature branch and switch to that branch git branch <name> git switch <name> Make whatever changes you intend to make. Stage changes an make commits as needed. git add * git commit -m \"<message describing change>\" Push changes to the origin branch. You must create the origin branch if it doesn't already exist. git push # or git push --set-upstream origin Create a Pull Request in GitHub or ADO. Approval of this PR will merge the changes with main/master. gitGraph commit commit branch ISSUE496 checkout ISSUE496 commit commit checkout main merge ISSUE496 commit commit Snippets Alias git config –global alias.stash ‘stash --all’ git config –global alias.bb !script.sh Logs git log --oneline git log -S files -p Diff git diff git diff --word-diff Commits git commit -m \"Commit message\" git commit -a -m \"Commit message\" git --amend Createing commits signed by GPG git config gpg.format ssh git config user.signingkey ~/.ssh/key.pub Maintenance git maintenance start Recover lost commit git reflog * copy the commit hash before the action that deleted git branch <branch name> <commit hash> * branch name = new branch name, commit hash = past commit hash from previous step Recover lost branch git reflog * copy the commit hash before the action that deleted git branch <branch name> <commit hash> * branch name = branch name that was deleted, commit hash = past commit hash from previous step Workflow Summary git clone <repo> git branch <branch name> git switch <branch name> <do stuff> git add * git commit -m “<commit message>” git push --set-upsteam origin <branch name> git switch main git merge <branch name> References The gitflow workflow - in less than 5 mins Learn Git Rebase in 6 minutes // explained with live animations! Git MERGE vs REBASE: The Definitive Guide Resolve Git MERGE CONFLICTS: The Definitive Guide Notes Workflow path and getting out of trouble git branch feature > git switch feature > (make changes) > git add * > git commit -m 'commit message' > git push > git switch main > git merge feature # if merge confict -> (edit confict file) -> git add * -> git commit -m 'commit message' if divergent branch error -> git switch feature -> git rebase main -> git switch main -> git merge feature"
  },
  "docs/git/rebaseing.html": {
    "href": "docs/git/rebaseing.html",
    "title": "Rebase | Crusader Two One",
    "keywords": "Rebase git rebase -i HEAD~3 Interactive Rebase Warning Do NOT use interactive rebase on commits that have already been pushed to remote repository git rebase feature_branch"
  },
  "docs/git/resolvingconflicts.html": {
    "href": "docs/git/resolvingconflicts.html",
    "title": "Resolving Merge Conflicts | Crusader Two One",
    "keywords": "Resolving Merge Conflicts Edit each of the conflict files to retain the code you want to retain. Stage the updated files and create a commit git add * git commit -m 'commit message'"
  },
  "docs/git/resolvingerrors.html": {
    "href": "docs/git/resolvingerrors.html",
    "title": "Resolving Errors | Crusader Two One",
    "keywords": "Resolving Errors Divergent Branch Error Describe the error git switch <feature branch> git rebase main # If main/master is not protected, you can then merge into that branch. Otherwise, create a PR to merge the changes into main/master. git switch main git merge feature"
  },
  "docs/git/ssh.html": {
    "href": "docs/git/ssh.html",
    "title": "SSH | Crusader Two One",
    "keywords": "SSH In most cases SSH will have to be used to authenticate to services such as Github, GitLab, and Azure DevOps. It is possible that more than one of these services could be used and each one may require a different SSH key or a configuration that is different than the others. Configuration files can be used to allow the setting of separate configurations without having to constantly change them when switching between services. VS Code works best with SSH for cloning. Config File The following config file will allow you to specify a specific SSH key for authenticating to Azure DevOps: Host vs-ssh.visualstudio.com HostName vs-ssh.visualstudio.com IdentityFile ~/.ssh/id_rsa_ado HostkeyAlgorithms +ssh-rsa PubkeyAcceptedAlgorithms +ssh-rsa IdentitiesOnly yes"
  },
  "docs/git/terminology.html": {
    "href": "docs/git/terminology.html",
    "title": "Terminology | Crusader Two One",
    "keywords": "Terminology The following will cover a number of terms that will be encountered thoughout the use of Git and related services. The relationship of these terms is somewhat circular, so you may have to read them all and then read them again to understand how they relate to each other. Index - A staging area where changes are stored before being committed to the working tree. Working Tree - The directory, including all its files and sub-directories that make up a repository. The top level of a working tree can be identified by the existence of a .git directory. Commit - A snapshot of the working tree at the time the commut was created. When a commit is created, the state of HEAD becomes that commit's parent. It is this parent relationship that is the basis for the concept of \"source control.\" HEAD - Defines what is currently checked out. HEAD symbolically refers to a branch that is checked out. If a specific commit is checked out (Detached HEAD), HEAD referes to that commit only. Repositoy - A repository is a collection or commits and defines which one is the HEAD. Branch - A name for a commit and it's parentage that defines history. Tag - Similar to a branch, it names a particular commit and can have it's own description. Master/Main - A branch that represents the mainline of development for a repository. Typically known as either master or main, may also be named trunk."
  },
  "docs/homeassistant/automations.html": {
    "href": "docs/homeassistant/automations.html",
    "title": "Automations | Crusader Two One",
    "keywords": "Automations"
  },
  "docs/homeassistant/deployment.html": {
    "href": "docs/homeassistant/deployment.html",
    "title": "Deployment | Crusader Two One",
    "keywords": "Deployment Setup mkdir homeassistant mkdir homeassistant/config Deploy Containers docker-compose up Update Containers The following commands will update the containers docker-compose build docker-compose down docker-compose up -d --force-recreate docker rmi $(docker images -f \"dangling=true\" -q) -f"
  },
  "docs/homeassistant/groups.html": {
    "href": "docs/homeassistant/groups.html",
    "title": "Groups | Crusader Two One",
    "keywords": "Groups This group will return \"home\" if any of the tracked devices are in the house ### Occupancy ################# house_occupancy: name: occupancy entities: - device_tracker.erin_s_s22_ultra - device_tracker.ghost_mobile all: false This group will return \"home\" if all tracked devices are in the house ### Occupancy ################# house_occupancy: name: occupancy entities: - device_tracker.erin_s_s22_ultra - device_tracker.ghost_mobile all: true"
  },
  "docs/homeassistant/guidlines.html": {
    "href": "docs/homeassistant/guidlines.html",
    "title": "Guidlines | Crusader Two One",
    "keywords": "Guidlines The purpose of this page is to lay out general guidlines for configuring Home Assistant in such a way as to maximize functionality and flexibility while limiting complexity as much as possible. Components Entities Template Sensors Groups Scripts Automations Areas Layers Layer 1 The first layer consists of the device entities themselves. Lights, sensors, devices, etc. Examples: Door/Window contact sensor Motion sensor Temperature sensor Smart thermostat Rest API Device states/attributes Layer 2 The second layer consolidates entity states using Template Sensors and Groups. Groups create a single representation of multiple entities of the same time to display a single status. Template sensors can be used to compare the values of multiple entities and present a value. Examples - Groups: Determin the status of any or all of the windows in the house Determin if anyone is home based tracked devices like mobile devices Example - Template Sensors: Compare the inside temperature with the outisde temperature to determine if the temperature outside is higher or lower than inside. Determin if the inside humidity is below 55% as the upper end of a comfortable range. Select data from a RestAPI sensor Additional Template Sensors are used to enable or disable functionality through conditions in automations Example - Binary Sensor Manually disable automations Trigger automations based on entity state(s) Layer 3 The third layer consists of Automations. Automations consist of triggers, conditions, and actions. Template Sensors and groups are used as triggers and conditions. Example 1: Trigger: A template sensor deterines that the outside temperature above 75 degrees, its warmer inside than than the outside, the inside humifity is greater than 55% Conditions: Some or all of the windows are open and the AC is off Action: Send a notification to a group of users to close the windows and turn on the AC Example 2: Trigger: A group of motion sensors detect motion Conditions: A group of tracked user devices shows that no one is home Action: Trigger an alert to a group of users that motion was detected in the house and turn on a scene for all inside lights Example Layer 4 THe fourth layer consists of Areas, Scripts, and Scenes that are executed by Automations. Layer 5 The fifth layer consists of Groups that are used to consolidate recipients for notifications"
  },
  "docs/homeassistant/index.html": {
    "href": "docs/homeassistant/index.html",
    "title": "Home Assistant | Crusader Two One",
    "keywords": "Home Assistant Description Home Assistant is... Containers Home Assistant Mosquitto MQTT Zigbee MQTT NodeRed References Home Assistant Home Assistant Github Using The Mosquitto_pub and Mosquitto_sub MQTT Client Tools- Examples Zigbee2Mqtt Issues"
  },
  "docs/homeassistant/sensors.html": {
    "href": "docs/homeassistant/sensors.html",
    "title": "Workday | Crusader Two One",
    "keywords": "Sensors Template Sensor - sensor: - name: \"AC_On_Window_Open state: > {% if states.binary_sensor.windows.state == 'off' and states.climate.thermostat.state == 'cool'-%} true {%- else -%} false {%- endif %} - sensor: - name: \"outdoor_temp\" state: > {% if (state_attr('climate.thermostat', 'current_temperature') | float <= states('sensor.oc_temp_upstairs_temperature') | float) %} Open Windows {% else %} Close Windows {% endif %} - sensor: - name: \"Average temperature\" unit_of_measurement: \"°C\" state: > {% set bedroom = states('sensor.bedroom_temperature') | float %} {% set kitchen = states('sensor.kitchen_temperature') | float %} {{ ((bedroom + kitchen) / 2) | round(1, default=0) }} Time of Day - platform: tod name: Night after: sunset before: sunrise - platform: tod name: Quiet TIme after: '21:00' before: '06:00' Workday - platform: workday country: US province: WI workdays: [mon, tue, wed, thu, fri] History Stats - platform: history_stats name: Lamp on today entity_id: light.my_lamp state: \"on\" type: time start: \"{{ now().replace(hour=0, minute=0, seconds=0 }}\" end: \"{{ now() }} - platform: history_stats name: Washer Running entity_id: sensor.washer_status state: \"running\" type: time end: \"{{ now() }}\" duration: days: 7 Utility - platform: history_stats name: Front Door Motion entity_id: binary_sensor.sensor.motion_front_door state: 'on' end: '{{ now() }}' duration: days: 7 utility_meter: hourly_frontdoor_motion: source: sensor.front_door_motion cycle: hourly daily_frontdoor_motion: source: sensor.front_door_motion cycle: daily Rest API binary_sensor: - platform: template sensors: nws_alerts_are_active: friendly_name: NWS Alerts Are Active #entity_id: sensor.nws_alerts value_template: > {{ states('sensor.nws_alerts') | int(0) > 0 }} icon_template: >- {% if states('sensor.nws_alerts') | int(0) > 0 %} mdi:weather-lightning {% else %} mdi:weather-sunny {% endif %}"
  },
  "docs/homeassistant/templates.html": {
    "href": "docs/homeassistant/templates.html",
    "title": "Templates | Crusader Two One",
    "keywords": "Templates View Entities State of an Entity {{ states.sensor.oc_temp_upstairs_temperature.state }} or {{ states('sensor.oc_temp_upstairs_temperature') }} Is State of an Entity Equal to 'x' {{ is_state('states.binary_sensor.oc_contact_bedroom_01_window_01_contact.state', \"off\") }} List the attributes of an Entity {{ states.light.kitchen_sink_light.attributes }} View the value of an attribute {{ state_attr('light.kitchen_sink_light', 'friendly_name') }} Manipulate Text Capitalize {{ states('light.kitchen_sink_light') | capitalize}} To Upper {{ states('light.kitchen_sink_light') | upper} To Lower {{ states('light.kitchen_sink_light') | lower} Concatination {% for state in states.sensor %} {{state.name ~ '=' ~ state.state }} {% endfor %} Join {% set output = namespace(sensors=[]) %} {% for state in states.sensor %} {% set output.sensors = output.sensors + [state.name ~ \"(\" ~ state.state ~ \")\"] %} {% endfor %} {{ output.sensors | join(',') }} Variables Set Variable {% set outside_temp = state_attr('climate.thermostat', 'current_temperature') %} Print variable {{ outside_temp }} Create an Array {% set my_array = (1,2,4,5) %} Create an Array from HA data {% set output = namespace(sensors=[]) %} {% for state in states.sensor %} {% set output.sensors = output.sensors + [state.name] %} {% endfor %} {{ output.sensors }} Math Subtraction {% set outside_temp = state_attr('climate.thermostat', 'current_temperature') %} {% set inside_temp = states('sensor.oc_temp_upstairs_temperature') %} {% set difference = (outside_temp | float - inside_temp | float) %} {{ difference }} Greater than or less than {% set outside_temp = state_attr('climate.thermostat', 'current_temperature') %} {% set inside_temp = states('sensor.oc_temp_upstairs_temperature') %} {% set difference = (outside_temp | float < inside_temp | float) %} {{ difference }} Average {% set outside_temp = state_attr('climate.thermostat', 'current_temperature') %} {% set inside_temp = states('sensor.oc_temp_upstairs_temperature') %} {% set average = (((outside_temp | float + inside_temp | float)) / 2) | round(2)%} {{ average }} Conditions For {%- for light in states.light -%} {%- if light.state == 'off' -%} {{ light.entity_id }}, {%- endif -%} {%- endfor -%} or {% set output = namespace(sensors=[]) %} {% for state in states.sensor %} {{ state.entity_id }} = {{ state.state }} {% endfor %} For (Print Index) {%- for light in states.light if light.state == 'off'-%} {{loop.index}} - {{ light.entity_id }} {% endfor %} For (filtered) {%- for light in states.light if light.state == 'off'-%} {{ light.entity_id }}, {%- endfor -%} Assign results of loop to an array {% set output = namespace(sensors=[]) %} {% for state in states.sensor %} {% set output.sensors = output.sensors + [state.name ~ ',' ~ state.state] %} {% endfor %} {{ output.sensors }} If/Else {% if is_state('climate.thermostat', 'cool') %} A window or door is open and the AC is on {% endif %} If/Else If {% if is_state('climate.thermostat', 'cool') %} The AC is on {% elseid %} The AC is off {% endif %} If with And/Or Logic {% if is_state('binary_sensor.oc_contact_bedroom_01_window_01_contact', 'on') or is_state('binary_sensor.oc_contact_bedroom_01_window_02_contact', 'on') or is_state('binary_sensor.oc_contact_livingroom_window_01_contact', 'on') or is_state('binary_sensor.oc_contact_door_patio_contact', 'on') or is_state('binary_sensor.oc_contact_office_window_contact', 'off') %} {% endif %} or {% if is_state('binary_sensor.oc_contact_bedroom_01_window_01_contact', 'off') and if is_state('climate.thermostat', 'cool') %} {% endif %} Nested If {% if is_state('binary_sensor.oc_contact_bedroom_01_window_01_contact', 'on') %} {% if is_state('climate.thermostat', 'cool') %} A window or door is open and the AC is on {% endif %} {% endif %} Snippets Show the state of an entity {{ states.binary_sensor.oc_contact_bedroom_01_window_01_contact.state }} {{ states.binary_sensor.oc_contact_bedroom_01_window_02_contact.state }} {{ states.binary_sensor.oc_contact_livingroom_window_01_contact.state }} {{ states.binary_sensor.oc_contact_door_patio_contact.state }} {{ states.binary_sensor.oc_contact_office_window_contact.state }} {{ states.climate.thermostat.state }} Alert if there is a door or window open when the AC is on {% if is_state('binary_sensor.oc_contact_bedroom_01_window_01_contact', 'on') or is_state('binary_sensor.oc_contact_bedroom_01_window_02_contact', 'on') or is_state('binary_sensor.oc_contact_livingroom_window_01_contact', 'on') or is_state('binary_sensor.oc_contact_door_patio_contact', 'on') or is_state('binary_sensor.oc_contact_office_window_contact', 'off') %} {% if is_state('climate.thermostat', 'cool') %} A window or door is open and the AC is on {% endif %} {% endif %} Show a filtered list of entities {{ expand(states.light) |selectattr('state', 'eq', 'off') |map(attribute='entity_id') |list }} Show all entities from an integraion {{ integration_entities('mqtt') }}"
  },
  "docs/homelab/index.html": {
    "href": "docs/homelab/index.html",
    "title": "Home Lab | Crusader Two One",
    "keywords": "Home Lab Services Proxmox Docker Terraform Ansible Grafana Bind9 OwnCloud"
  },
  "docs/index.html": {
    "href": "docs/index.html",
    "title": "This is the HOMEPAGE | Crusader Two One",
    "keywords": "This is the HOMEPAGE Refer to Markdown for how to write markdown files. Quick Start Notes Add images to the images folder if the file is referencing an image."
  },
  "docs/introduction.html": {
    "href": "docs/introduction.html",
    "title": "Knowledge Base | Crusader Two One",
    "keywords": "Knowledge Base This serves as my personal knowledge base. An online notebook of sorts for information I would like to store for later use. Topics PowerShell Docker Secure Shell Git SQL Unifi Networking Home Lab Home Assistant Terraform Ansible"
  },
  "docs/kql/index.html": {
    "href": "docs/kql/index.html",
    "title": "Kusto Query Language | Crusader Two One",
    "keywords": "Kusto Query Language Azure Log Analyitics Workspaces Threat Hunting All Sign-ins from IPs used by known bad actors let IPAddresses = SigninLogs | where TimeGenerated > ago(30d) | where UserPrincipalName in (\"user1@domain.com\", \"user2@domain.com\", \"user3@domain.com\", \"user4@domain.com\") | distinct IPAddress; SigninLogs | where TimeGenerated > ago(30d) | where IPAddress in (IPAddresses) | project TimeGenerated, UserPrincipalName, IPAddress, AppDisplayName, LocationDetails, ResultDescription | order by UserPrincipalName | distinct UserPrincipalName Defender Advanced Threat Hunting Email Activity All messages sent to \"edu-noreply@github.com\" EmailEvents | where SenderMailFromAddress endswith \"edu-noreply@github.com\" | project Timestamp, SenderFromAddress, SenderMailFromAddress, RecipientEmailAddress, Subject | distinct RecipientEmailAddress Users sending more than 700 messages in one day EmailEvents | where EmailDirection == \"Outbound\" | where SenderFromAddress !startswith \"mailer\" | project Timestamp, SenderFromAddress, SenderMailFromAddress, RecipientEmailAddress, Subject | summarize count_ = count() by bin(Timestamp, 1d), SenderFromAddress | where count_ >= 700 Number of messages sent by a user EmailEvents | where RecipientEmailAddress == \"salewis1@madisoncollege.edu\" | summarize count_ = count() by SenderMailFromAddress | order by count_ Messages sent by a list of users EmailEvents | where RecipientEmailAddress in (\"user1@domain.com\", \"user2@domain.com\", \"user3@domain.com\", \"user4@domain.com\") | project Timestamp, SenderMailFromAddress, RecipientEmailAddress, Subject, LatestDeliveryLocation, LatestDeliveryAction All Spam and Phishing Messages sent to a list of users EmailEvents | where RecipientEmailAddress in (\"user1@domain.com\", \"user2@domain.com\", \"user3@domain.com\", \"user4@domain.com\") | where ThreatTypes == @\"Phish, Spam\" Authentication AiTM Attack Authentication let OfficeHomeSessionIds = AADSignInEventsBeta | where Timestamp > ago(1d) | where ErrorCode == 0 | where ApplicationId == \"4765445b-32c6-49b0-83e6-1d93765276ca\" //OfficeHome application | where ClientAppUsed == \"Browser\" | where LogonType has \"interactiveUser\" | summarize arg_min(Timestamp, Country) by SessionId; AADSignInEventsBeta | where Timestamp > ago(1d) | where ApplicationId != \"4765445b-32c6-49b0-83e6-1d93765276ca\" | where ClientAppUsed == \"Browser\" | project OtherTimestamp = Timestamp, Application, ApplicationId, AccountObjectId, AccountDisplayName, OtherCountry = Country, SessionId | join OfficeHomeSessionIds on SessionId | where OtherTimestamp > Timestamp and OtherCountry != Country"
  },
  "docs/pgp/01-summary.html": {
    "href": "docs/pgp/01-summary.html",
    "title": "Summary | Crusader Two One",
    "keywords": "Summary The purpose of this post is to explain what PGP is and how to use it to secure communications. While frequently PGP is used together with other tools for anonymity, like Tor or I2P, that is not the purpose of this guide. The PGP encrypted messages do not have to be sent over email. Messages can be easily sent over SMS, Facebook, or any application that will allow you to paste in the encrypted message. The message could also be contained in an encrypted file and sent as an attachment or stored in a shared file system. This guide you will cover the basic tasks required to install a PGP application, create a PGP keypair, encrypt, decrypt, sign, and verify messages, as well as how store, share, and retrieve keys using a public key server. Applications to enable the use of PGP are available for Windows, Mac, Linux, and mobile devices. This guide will use Kleopatra and GPA as part of the GPG4Win application, or GPG4Win portable, to enable this capability on Windows hosts. The GPG4Win Portable application will allow you to store the application and your keys on a USB device so that it can be used without having to install the application. It can also be run from the local file system for situations when you can't install applications and are prevented from mounting removable media. One thing to keep in mind is that PGP cannot protect your messages from situations where the plaintext message may be captured before it is encrypted. For example, a key logger installed on the host used to create the message before it is encrypted will capture the keystrokes used when crafting the message. Also, do not create your messages in a service like Gmail, as the text that you entered could be saved automatically as a \"draft\" within your account by the service. Instead, craft the message in notepad and only paste the message into Gmail once it is encrypted. PGP Background (Wikipedia) https://en.wikipedia.org/wiki/Pretty_Good_Privacy Pretty Good Privacy is a data encryption and decryption computer program that provides cryptographic privacy and authentication for data communication. PGP is often used for signing, encrypting, and decrypting texts, e-mails, files, directories, and whole disk partitions and to increase the security of e-mail communications. To the best of publicly available information, there is no known method which will allow a person or group to break PGP encryption by cryptographic or computational means. Indeed, in 1995, cryptographerBruce Schneier characterized an early version as being \"the closest you're likely to get to military-grade encryption.\"["
  },
  "docs/pgp/02-concepts.html": {
    "href": "docs/pgp/02-concepts.html",
    "title": "Concepts | Crusader Two One",
    "keywords": "Concepts PGP allows us to perform one or more of the following tasks; encrypt, decrypt, sign, or verify. This section will describe each of these tasks. It is important to understand how the pubic and private keys are used and by whom for each of these tasks. Creating Keypairs Managing KeyPairs Encryption takes the recipient's public key and scrambles a message. This scrambled text is only able to be unscrambled by the recipient's private key. The sender always encrypts with the recipient's public_ key_. Decryption takes a message that has been encrypted using the recipient's public key and descrambles it using the recipient's private key and the passphrase associated with that private_ key. The recipient always decrypts with the recipient's private_ key. Signing a message authenticates the author the message and provides cryptographic integrity. In other words, it ensures that the message was authored by the owner of the keypair that it was signed with and that it was not tampered with in transit. The sender always signs a message with the sender's private_ key and the passphrase associated with it. Verifying_ a message is the process of analyzing a signed message, to determine if the signing is true. Signing and verifying can be thought of as opposites. Warning Signing a message does not obscure the contents of the message; it only authenticates the sender and verifies that the message hasn't been altered. However, an encrypted message can also be signed by the author. Putting It All Together The sender of the message must retrieve the recipient's public key. The sender can aquire the public key in a number of ways; sent via email, copied off the recipient's web page or business card, downloaded from a key server, or any other method. The key point to remember is that the public key is \"public\", so it doesn't really matter how the the sender gets the public key. The message is composed by the sender and encrypted with the recipient's public key resulting. The resulting cyphertext is copied and pasted into an email, SMS message, Facebook post, chat message, etc. and sends it. It is important to note that only the encrypted text is secured. In the case of email, the sender and recipient's email addresses, subject, and message headers, and other information is still sent in plaintext. The recipient uses his own private key, unlocked with the private key's password, to decrypt the cyphertext message. This is what makes the private key so important. Only someone with the private key and password, that is from the same key pair as the public key used to perform the encryption, can decrypt the message. When Should I Sign? When Should I Encrypt? It is not necessary to sign and encrypt every outgoing email. Understanding how the signing and encrypting of messages achieves confidentiality and authentication will help you choose which method, if any, should be used. Confidentiality - Ensuring that the message can only be read by its intended audiance Authentication - Validating that the message was sent why who it appears sent it (non-repudiation) and that it was not tampered with in transit (integrity) The three available choices are: Do nothing: The contents of the message is not confidential and authentication is not important, the message can be sent in plain text. Sign (not encrypted): Message authentication is important, but the contects of the message are not confidential, sign the message, but do not encrypt. Sign and Encrypt: If the contents of the email are confidential, sign and encrypt. While possible to encrypt a message without signing, if the message is important enough to encrypt, it is important enough to be be signed For 90% of messages most people send, signing and encrypting is not necessary. The remaining 10% of the time may require signing and encrypting confidential information (i.e. Personally Identifiable Information (PII), credit card information, bank numbers, social security numbers, corporate strategies, etc. The need for signing only will likely be rare. Sending PGP Encrypted Attachments (a.k.a., PGP MIME type) vs Sending Cyphertext (a.k.a., PGP INLINE) Nothing is gained from sending the message as an attachments, so it ends up being extra steps for no reason. Inline text works places where attachments don't (the shell, Facebook, iMessage, etc.). Many applications and email clients do not have built in PGP capabilities or available plugins requiring sedning inline anyway. Using Mail Client PGP Plugins (i.e., Mail.app PGP plugin) Relying on mail client plugins can result in a false sense of security. Unless you have access to the source code and are willing to review it, users have no idea what the plugins may be doing. When a plugin generates an attachment and sends it before you can see what is going on, you have no idea what is happening or if it is working."
  },
  "docs/pgp/04-install-clients.html": {
    "href": "docs/pgp/04-install-clients.html",
    "title": "Install Clients | Crusader Two One",
    "keywords": "Install Clients GPG (Linux) Redhat/CentOS sudo yum install gnupg Debian/Ubuntu sudo apt update sudo apt install gnupg GPG4Win (Windows) GnuPG/Gnu Privacy Assistant (Linux) iPhone (IPGMail) Mac OS (GPG Suite) Download: http://gpg4win.org/download.html Make sure that Kleopatra and GNU Privacy Assistant (GPA) are installed. GPA is not selected as an option by default. Either Kleopatra or GPA can be used to encrypt and decrypt messages. Choose your language, click \"Ok\" Click \"Next\", then \"Next\" again. You\"ll now be at a screen asking what components you want to install. We'll be selecting \"Kleopatra\", \"GpgEX\", and \"Gpg4win Compendium\". Then click \"Next\" It will ask where to install, just keep the default and click \"Next\" Now it'll ask where you want to install shortcuts. Select whichever you want, click \"Next\" You can choose which Start Menu folder you want it installed in, just click \"Next\" It will now install, when done you should see this. Click \"Next\", then \"Finish\" Like I said in the intro, we'll be using GnuPG with Gnu Privacy Assistant. I like GPA as a graphical front-end because its layout is really easy to understand and follow. Open up Terminal Type, without quotes, 'sudo apt-get install gpa gnupg2', then hit 'enter' Enter your password, hit 'enter' It will pull the dependancies needed for both to work properly, tell you the space needed, and ask you to confirm. Type 'y' then hit 'enter' to confirm Wait a bit as everything installs This should only take a few minutes to complete. See this picture to confirm you're doing the steps correctly: &lt;…&gt;"
  },
  "docs/pgp/05-command-line.html": {
    "href": "docs/pgp/05-command-line.html",
    "title": "Command Line (gpg.exe) | Crusader Two One",
    "keywords": "Command Line (gpg.exe) Install Create PGP Keypair Before you can encrypt or sign files with GPG you must have a key. gpg --gen-key Retrieve the Public Key Post the public, ascii side of your key to the web gpg --import key.asc gpg --list-keys Publish the Public Key gpg --armor --output public.asc --export <Your Name>; gpg --send-keys <Your Name> --keyserver hkp://subkeys.pgp.net gpg --search-keys <myfriend@his.isp.com> --keyserver hkp://subkeys.pgp.net Obtain the Private Key gpg --armor --export-secret-key --output private.asc --export <Your Name> Importing a Private Key gpg Encrypting a Message Here we encrypt/decrypt a file that is just for our own use. gpg --encrypt --recipient <Your Name> foo.txt Encrypting for Recipient gpg --encrypt --recipient <myfriend@his.isp.net> foo.txt Decrypting a Message gpg --output foo.txt --decrypt foo.txt.gpg Revoke a key gpg --gen-revoke --output revoke.txt --export <Your Name> Signatures gpg --verify crucial.tar.gz.asc crucial.tar.gz gpg --armor --detach-sign your-file.zip"
  },
  "docs/pgp/06-gpg4win.html": {
    "href": "docs/pgp/06-gpg4win.html",
    "title": "Windows (GPG4Win) | Crusader Two One",
    "keywords": "Windows (GPG4Win) Install Download: http://gpg4win.org/download.html Make sure that Kleopatra and GNU Privacy Assistant (GPA) are installed. GPA is not selected as an option by default. Either Kleopatra or GPA can be used to encrypt and decrypt messages. Choose your language, click “Ok” Click “Next”, then “Next” again. You”ll now be at a screen asking what components you want to install. We’ll be selecting “Kleopatra”, “GpgEX”, and “Gpg4win Compendium”. Then click “Next” It will ask where to install, just keep the default and click “Next” Now it’ll ask where you want to install shortcuts. Select whichever you want, click “Next” You can choose which Start Menu folder you want it installed in, just click “Next” It will now install, when done you should see this. Click “Next”, then “Finish” Create PGP Key Pair Kleopatra The next step is to generate your keypair so you can encrypt/decrypt messages. Like always, we’ll be going with 4096 bit RSA. You will create a Public and Private key pair with information related to your identity and email address or addresses. This is important to help others locate your public key on the key server. If we were concerned with anonymity, we would make sure that none of the information used in the key pair could be used to reveal our true identity. The e-mail could be a valid alias for an anonymous email service on the DarkNet or complete gibberish. Kleopatra should be used to create your key pairs instead of GPA because it will allow you to create a 4096 bit RSA key where GPA will only allow you to create a 2048 bit RSA key. Open up Kleopatra application Click “File”, then “New Certificate…” In the Certificate Creation Wizard click “Create a personal OpenPGP key pair” Enter your personal information, but do not click Next yet. Click “Advanced Settings…”, and in the Advanced Settings dialog box in the “Key Material” section select the “RSA” radio button, select “4,096 bits” from the drop-down menu, and click “Ok” Verify that the information you entered your information correctly and click “Create Key” Enter a secure passphrase in the “pinentry” dialog box and click “Ok” Kleopatra will now generate the key pair. The random entry of data is used to create entropy. Enter text, move the mouse, etc. Once the key is created, click “Finish” GPA Next, you want to make a PGP key. Remember, none of the details need to be valid. I'd use your online name or a different alias when making your key. Something that isn't your gamertag for online games, or anything that may tie to you. A completely new alias. The e-mail doesn't need to be valid at all. Here are some pictures to help you through the process. Also, make a backup of your key!!! First, click the keys in the menu at the top. Alternatively, you can click CTRL+N to begin the process of creating a key. Shown here: You will go through a set-up, where you make a name for your key, which I suggest you use an alias. Shown here: After selecting your alias, it asks for an e-mail address. This e-mail should be non-existent, and be linked to a website that also doesn't exist. Shown here: Then you're asked to make a backup of your key. I highly suggest you do this! Although you can make a back up at any time, you should just do it now. This is where your public key will be that you give to others to contact you. Shown here: Find where you put the back up of your key. It will be an .asc file but no worries, when asked to open the file just tell windows or whatever OS to open it using Notepad. Here you will find a public key similar to this. When sharing your key with others, you want to copy and paste from the beginning dashes to the end dashes. Exactly how I have copied and pasted above. Publish the Public Key to a Key Server Kleopatra Key Publish Add your public key to a public key server so people can find your public key in order to send you secure messages. GPA Key Publish Add your public key to a public key server so people can find your public key in order to send you secure messages. A public key can be published to a key server from GPA by clicking on the “Server” menu and selecting “Send Keys.” Retrieve Public Keys Kleopatra Retrieve Public Keys In this step we are going to retrieve the public key from the key pair that was just created. By doing this we are able to make the public key available to those that wish to communicate with you securely. Without it, they will not be able to encrypt messages that you are able to decrypt. In the “My Certificates” tab, right click on your key and click “Export Certificates…” Browse to the location where you want to save the public key and click “Save” (Note: you may want to give it a name that distinguishes this file as your public key) The public key can be viewed in a text editor, like notepad. Browse to the location where you saved the key and open it. (Note: The key will have a “.asc” extension, you may have to select “All files” from the dropdown menu. The text you see in the file is your public key. This is the text that you will send to others so they can import it into their PGP application. GPA Retrieve Public Keys <…> Obtaining the Private Key Kleopatra Obtaining the Private Key Similar to obtaining your public key Right click on your key in the “My Certificates tab and select “Export Secret Keys…” Select the location to save your private key, give it a name, check “ASCII armor”, and click “Ok” The following dialog box confirms the export of your private key. (Remember to keep the private key safe and never share it!) GPA Obtaining the Private Key <…> Importing a Public Key Kleopatra Importing a Public Key It’s impossible to send a vendor an encrypted message without their public key. The public key could be sent to you in an email as an attachment or included in the signature block, downloaded from a key server, shared from removable storage, etc. Receive a public key as a text file through email or other electronic method Copy all text including “—–BEGIN PGP PUBLIC KEY BLOCK—–” and “—–END PGP PUBLIC KEY BLOCK—” In your task bar, right click on the Kleopatra icon, go to “Clipboard”, then click “Certificate Import” If the import worked you should see a window pop up as confirmation, click “Ok” The imported key should now be displayed in Kleopatra under the “Other Certificates” tab GPA Importing a Public Key <…> Importing the Private Key Kleopatra Importing the Private Key The private key that you will be importing is from a key pair that you have previously created. This private key is used to sign outgoing messages and to decrypt incoming messages. Any host or device that contains your private key should be considered “sensitive” because loss or theft could lead to the compromise of your private key. Click “File”, “Import Certificates…” Browse to the location where the private key is saved, select it, and click “Open” A window will be displayed confirming the import of the private key. Click “Ok” to contintue. The key information should now be displayed in the “My Certificates” tab GPA Importing the Private Key You see people giving their public keys away so others can contact them. Simply open a notepad file, copy and paste their key and import it using the GPA program. I will show you how to do this. First make a blank text file and copy the users pubic key to it. Shown here: Then, in the Keys menu where you made your key, select import keys. Shown here: Encrypting a Message Kleopatra Encrypting a Message To create a message and encrypt it: Open Notepad and create your message Copy the entire message to the clipboard In your task bar, right click on the Kleopatra icon, go to “Clipboard”, then click “Encrypt…” This gorgeous window will open. Click “Add Recipient…” Another window will appear. Click the “Other Certificates” tab, then select who you want to send your message to, then click “Ok”. You should be back at the previous window with the recipient listed. Click “Next” If all went well, you should see this window. Click “Ok” Your encrypted message will be in your clipboard, all you need to do is paste it into the message box and send GPA <..> Decrypting a Message Kleopatra Decrypting a Message This is just as easy as encrypting. Copy everything that was sent In your task bar, right click on the Kleopatra icon, go to “Clipboard”, then click “Decrypt/Verify…” A window will pop up asking for your passphrase, enter that then click “Ok” A window should pop up verifying it was decrypted, and copied to your clipboard. Click “Finish” Open your text editor of choice, and paste your message GPA Decrypting a Message <…>"
  },
  "docs/pgp/07-advanced.html": {
    "href": "docs/pgp/07-advanced.html",
    "title": "Advanced | Crusader Two One",
    "keywords": "Advanced Securely Composing Email Metadata Metadata provides the context to the content of the email. Protecting the email content (with PGP) will significantly enhance the security of the communication. Frequently, the context (the metadata) is sufficient to learn a great deal about the communication even without the content. Unfortunately, even PGP encrypted email leaves communications metadata exposed, this includes: Subject To From Dates and times IP addresses email application Minimizing the contextual information leakage from the email starts with knowing what metadata will be exposed. Where possible, and relevant, take control over that information and unlink it from data linked to you. For example, you can control the From field by creating a new email account. The IP address of the sending email client can be changed by using a VPN, Tor, or a public Internet connection. One option to consider is the use of Tor. The usual caveats about Tor apply: do not rely exclusively on Tor, if you need to protect your IP address then use an IP address that is not attributable to you. The Subject There is little else you can do about the To, From, and IP, as those are controlled by the infrastructure. However, you have complete control over the Subject. All acceptable subjects are listed below: ... xxx ;;; ::: &lt;space&gt; The Subject must never ever refer to the content of the email, even obliquely. For example, \"Subject: Your cocaine has shipped!\" is a total email security failure. Subjects should be empty! Disable the Warn about empty subject setting on your email client Writing There are fundamentally two options when composing an email: you can either write the email in a text editor, or in an email client. For security, that is, control over the process, a text editor is safer. For convenience most people will use their email client. Safest Write in a text editor Encrypt on the command line Only expose already-encrypted data to the email client Realistic At least restrict the plaintext to the local system you control Drafts Don't save Drafts in plaintext Drafts can be a significant source of risk. The storage and handling of drafts must be approached with care. Make sure that they are encrypted (never stored in plaintext), that they are stored locally (where you can be sure of deleting them) and that they are deleted after use. Make sure to configure your email client to store drafts locally and to encrypt them before writing them to disk. Don't store on server Ensure they are encrypted Ensure they are deleted after use Composition Delete the content in a reply, only quote the relevant parts if necessary Mitigate against the potential threat of any single email being compromised by limiting the information within any single email. The more information is stored in the mental context of the correspondents, the less useful the information in the email is to an adversary. Wherever possible minimize the amount of irrelevant contextual information within the email body. Keep it short, simple, and clean. Attachments PGP has all the capability of tar or zip. It is possible to include all the files you need to include as a pure PGP messages without having an attachment called secret-leaked-nsa-docs.tar.gz.gpg.asc. The program to use is gpg-zip and it takes both --tar= command line options and gpgcommand line options. Use this to bundle your files and send them as an opaque encrypted blob. Encrypting use --throw-keys to prevent leaking more metadata PGP encryption stores metadata about the decryption keys in the encrypted data. This is a simple optimization to allow the recipient to rapidly determine whether the email can be decrypted by a private key they possess. This information also allows an attacker to determine who can read the email. If the email is intended to be truly anonymous, this metadata must be discarded. Fortunately, there is a gpg command line flag for this: --throw-keys. Ensure that --throw-keys is added to the command line when encrypting data. PGP/MIME and inline PGP -ear aren't the same. For more control and compatibility, use inline PGP. Sending Ensure you encrypt by default Accidentally sending an unencrypted email is a potentially fatal error. Configure your email client to always encrypt by default. If you want to send a plaintext email, then deliberately set that option. Think about signing Signing an email provides guarantees that the content was written by someone that possess the private key. That it is, it positively identifies at least one person involved in the email exchange. Think carefully about whether you want to be positively identified as the author of the email. Set your email client to not sign messages by default. Sign messages explicitly. Store sent messages locally, then delete them After the email has been sent and is no longer operationally useful, delete it. To make sure that you can do this, configure your email client to store your Sent messages locally. When in doubt, store locally. At least you will have some control over whether it is thoroughly deleted. Receiving Delete emails after they are no longer necessary INBOX ZERO OUTBOX ZERO DRAFTS ZERO TRASH ZERO Regularly delete all emails. Easiest way is to set the Trash to erase everything after 30 days, and then delete every email after it has been processed. Riseup.net PGP Configuration Guide There is a PGP configuration guide from riseup.net. If you want to incorporate their best practice recommendations without any of their terrible advice about using key servers etc, then simply install this gpg.conf into your ~/.gnupg. gpg.conf Outreach Remind your correspondents to practice the same PGP hygiene"
  },
  "docs/pgp/08-conclusion.html": {
    "href": "docs/pgp/08-conclusion.html",
    "title": "Conclusion | Crusader Two One",
    "keywords": "Conclusion This should provide you with enough information to get started with PGP/GPG on a Windows host. While PGP can seem complicated at first it\"s actually pretty simple. With this technology you can secure nearly all of your electronic communications."
  },
  "docs/pgp/09-references.html": {
    "href": "docs/pgp/09-references.html",
    "title": "References | Crusader Two One",
    "keywords": "References https://www.deepdotweb.com/2015/02/21/pgp-tutorial-for-windows-kleopatra-gpg4win/ https://www.deepdotweb.com/2013/11/11/pgp-tutorial-for-newbs-gpg4win/ https://en.wikipedia.org/wiki/Pretty\\_Good\\_Privacy http://notes.jerzygangi.com/the-best-pgp-tutorial-for-mac-os-x-ever/ http://www.techrepublic.com/blog/it-security/using-gnupg-encryption-tools-with-gpg4win/ https://gpgtools.tenderapp.com/kb/how-to/first-steps-where-do-i-start-where-do-i-begin-setup-gpgtools-create-a-new-key-your-first-encrypted-mail https://github.com/nask0/Operational-PGP http://edoceo.com/cli/gpg https://riseup.net/en/security/message-security/openpgp/best-practices https://riseup.net/en/security/message-security/openpgp/gpg-keys https://blog.dest-unreach.be/2009/04/13/the-internals-of-a-gpgpgp-key https://futureboy.us/pgp.html https://www.poftut.com/install-use-gpg-encrytion-linux-order-encrypt-decrypt-files-folder/"
  },
  "docs/pgp/10-glossary.html": {
    "href": "docs/pgp/10-glossary.html",
    "title": "Glossary | Crusader Two One",
    "keywords": "Glossary References PGP – Pretty Good Privacy GPG4Win – An OpenGPG compliant application for Windows GPG4Win Portable – A GPG4Win application designed to be run from a thumb drive Key pair – Public and Private keys generated by a PGP user Public key – Key used to encrypt a message to be sent Private key – Key used to decrypt a message that has been received Key server – A publicly available repository of public PGP keys Tor – Client used to provide anonymity and access to the DeepWeb I2P – Client used to provide anonymity and access to the DeepWeb iPGMail – A PGP client for the iPhone Tails – A Linux distribution that combines Tor, PGP, Pidgin OTR, and others for anonymous communications Pidgin Off The Record (OTR) – An add-on to the Pidgin chat application that provides PGP encrypted chat capability"
  },
  "docs/pgp/index.html": {
    "href": "docs/pgp/index.html",
    "title": "Electronic Message Security with GPG | Crusader Two One",
    "keywords": "Electronic Message Security with GPG"
  },
  "docs/powershell/Functions.html": {
    "href": "docs/powershell/Functions.html",
    "title": "Functions | Crusader Two One",
    "keywords": "Functions"
  },
  "docs/powershell/activedirectory.html": {
    "href": "docs/powershell/activedirectory.html",
    "title": "Active Directory | Crusader Two One",
    "keywords": "Active Directory Remove ACE from a list of object's ACL for a security principal function Remove-ADObjectACE() { [CmdletBinding()] Param ( $ADObject, $SecPrincipal ) Write-Output (\"Removing {0} from {1}\" -f $SecPrincipal, $ADObject.name) Try { $Acl=(get-acl -path $ADObject.distinguishedname) $Ace = $Acl.access | ?{ $_.IsInherited -eq $false -and $_.IdentityReference -eq $SecPrincipal } if ($Ace) { $Acl.RemoveAccessRule($ace) Set-Acl -Path $ADObject.DistinguishedName -AclObject $Acl -ErrorAction Stop Return } else { Write-Output (\"No ACL to remove from {0}\" -f $ADObject.name) } } catch { Write-Error $_.exception.message } } $SecPrincipal = \"AD\\Domain Admins\" $ADObjects = Get-ADGroup -Filter * -SearchBase \"OU=groups,OU=managed,DC=ad,DC=domain,DC=com\" foreach ($ADObject in $ADObjects) { Remove-ADObjectACE -ADObject $ADObject -SecPrincipal $SecPrincipal -ErrorAction Stop }"
  },
  "docs/powershell/conditions.html": {
    "href": "docs/powershell/conditions.html",
    "title": "Conditions | Crusader Two One",
    "keywords": "Conditions"
  },
  "docs/powershell/errorhandling.html": {
    "href": "docs/powershell/errorhandling.html",
    "title": "Error Handling | Crusader Two One",
    "keywords": "Error Handling What is Error Handling Error handling is a crucial aspect of programming that involves anticipating and managing errors or exceptions that may occur during the execution of a script or program. It is a way to protect resources and ensure that the program behaves as expected, even when unexpected situations arise. Error handling allows developers to gracefully handle errors, provide meaningful feedback to users, and prevent the program from crashing or causing unintended consequences. By implementing error handling techniques, such as try-catch blocks or error logging, developers can identify and handle errors in a controlled manner, improving the reliability and robustness of their code. The Difference Between Terminating and Non-Terminating Errors Terminating errors, known as exceptions, terminate the execution process. Non-terminanting errots will cause an error message to be written the error stream, but theh script will continue to execute. PowerShell ErrorAction The following ErrorAction options available with the $ErrorActionPreference and -ErrorAction parameters: Continue: Writes the error to the pipeline and continues executing the command or script. This is the default behavior in PowerShell. Ignore: Suppresses error messages and continues executing the command. The errors are never written to the error stream. Inquire: Pauses the execution of the command and asks the user how to proceed. Cannot be set globally with the $ErrorActionPreference variable. SilentlyContinue: Suppresses error messages and continues executing the command. The errors are still written to the error stream, which you can query with the $Error automatic variable. Stop: Displays the error and stops executing the command. This option also generates an ActionPreferenceStopException object to the error stream. Suspend: Suspends a workflow that can later be resumed. The Suspend option is only available to workflows. Throw Throw Trap Trap Try/Catch/Finally Try/Catch/Finally References \"Everything you wanted to know about Exceptions\""
  },
  "docs/powershell/index.html": {
    "href": "docs/powershell/index.html",
    "title": "PowerShell | Crusader Two One",
    "keywords": "PowerShell Put the \"investment quote\" here."
  },
  "docs/powershell/introduction.html": {
    "href": "docs/powershell/introduction.html",
    "title": "Introduction | Crusader Two One",
    "keywords": "Introduction"
  },
  "docs/powershell/loops.html": {
    "href": "docs/powershell/loops.html",
    "title": "Loops | Crusader Two One",
    "keywords": "Loops"
  },
  "docs/powershell/moduledev.html": {
    "href": "docs/powershell/moduledev.html",
    "title": "Module Development | Crusader Two One",
    "keywords": "Module Development Introduction This document will outline creating PowerShell modules using Plaster and an opinionated PLaster template called Stucco. Plaster and Stucco will create the scaffolding needed to organize the files needed to create and publish the PowerShell module. This includes creating Pester tests to ensure that the module meets the defined requirements. Prerequisites PowerShell This document is written using the latest version of PowerShell at the time of its writing, version 7.4.2. Using PowerShell greater than PowerShell 6 (i.e. Windows PowerShell) provides many more features, not the least of which is the ability to be used cross-platform. Visual Studio Code Just as will PowerShell, the latest version of Visual Studio Code at the time of the writting of this document was used, version 1.89.0. PowerShell Modules The following modules must also be installed: Plaster (1.1.4) Pester (5.5.0) PSScriptAnalyzer (1.22.0) The following code will install the modules needed to begin: install-module plaster, pester, psscriptanalyzer Stucco While Plaster comes with default templates and you can create your own templates, this document uses the Stucco template. The Stucco template can be aquired by cloning the Stucco repository on GitHub. You can clone the repository directly to the location where Plaster looks for templates or you can copy it there from whatever location you choose to clone it to. git clone https://github.com/devblackops/Stucco.git Find the location of the Plaster templates by executing the following command: Get-PlasterTemplate | select TemplatePath TemplatePath ------------ /home/hades/.local/share/powershell/Modules/Plaster/1.1.4/Templates/AddPSScriptAnalyzerSettings /home/hades/.local/share/powershell/Modules/Plaster/1.1.4/Templates/LocalTemplate /home/hades/.local/share/powershell/Modules/Plaster/1.1.4/Templates/NewPowerShellScriptModule /home/hades/.local/share/powershell/Modules/Plaster/1.1.4/Templates/PlasterTemplate /home/hades/.local/share/powershell/Modules/Plaster/1.1.4/Templates/Stucco/Stucco Create Module Scaffolding The module scaffolding is created by executing the following command: Invoke-Plaster -TemplatePath 'C:\\path\\to\\templates\\PlasterTemplate' The Invoke-Plaster cmdlet will show a number of prompts to which the details of the module can be selected. Stucco Parameters: ModuleName (Name of the Module) Description (Description of the Module) Version (Module Version) FullName (User Full Name) License (License for the Module) CoC (Code of Conduct) MkDocs (MkDocs Support) MkDocsSiteName (MkDocs Repo URL) Classes (Will PowerShell classes be used?) PlatyPS (PlatyPS for documentation?) devcontainer (Use VSCode Dev Container support?) CICD (Include CI/CD support) Another method is to provide the answers to those prompts to the cmdlet at the time of execution. The parameters can easily be splatted as seen below: $Params = @{ TemplatePath = 'C:\\path\\to\\templates\\PlasterTemplate' DestinationPath = '.\\' Name = 'NameOfModule' Description = 'Description of the Module' Version = '0.9.0' FullName = 'Author Name' License = 'None' CoC = 'No' MkDocs = 'No' Classes = 'Yes' PlatyPS = 'No' devcontainer = 'No' CICD = 'AzurePipelines' } Invoke-Plaster @Params Create Code for the Module When writing the code for the module, write each function in a separate .ps1 file. Place the .ps1 file into the Public or Private directory as needed. Build Module .\\build.ps1 Publish Module publish-Module Publish Module CI/CD name: build"
  },
  "docs/powershell/modulerepo.html": {
    "href": "docs/powershell/modulerepo.html",
    "title": "Module Repositories | Crusader Two One",
    "keywords": "Module Repositories Private Repositories BaGet BaGet is... The following Docker Compose file can be used to run BaGet. version: '3.7' volumes: baget-data: name: baget-data networks: internal-net: name: internal-net driver: bridge services: baget: image: loicsharma/baget:latest container_name: baget restart: always environment: - ASPNETCORE_ENVIRONMENT=Production - Storage__Type=FileSystem - Storage__Path=/var/baget/packages - Database__Type=Sqlite - Database__ConnectionString=Data Source=/var/baget/baget.db - Search__Type=Database - ApiKey=MySecretApi - AllowPackageOverwrites=true - PackageDeletionBehavior=HardDelete - Mirror__Enabled=true volumes: - baget-data:/var/baget ports: - 5555:80 networks: - internal-net The following command will register BaGet as a PSRepository: $Params = @{ Name = \"BaGet\" SourceLocation = \"http://localhost:5555/v3/index.json\" PublishLocation = \"http://localhost:5555/api/v2/package\" InstallationPolicy = \"Trusted\" } Register-PSRepository @Params THe following commands used to find, install, upgrade, and remove a module from the BaGet PSRepository # Find a module Find-Module -Name \"ModuleName\" -Repository \"BaGet\" # Install module Install-Module -Name \"ModuleName\" -Repository \"BaGet\" # Update module Update-Module -Name \"ModuleName\" -Repository \"BaGet\" # Uninstall Module Uninstall-Module -Name \"ModuleName\" The ...."
  },
  "docs/powershell/modules.html": {
    "href": "docs/powershell/modules.html",
    "title": "Modules | Crusader Two One",
    "keywords": "Modules"
  },
  "docs/powershell/powershellrunspaces.html": {
    "href": "docs/powershell/powershellrunspaces.html",
    "title": "PowerShell Runspaces | Crusader Two One",
    "keywords": "PowerShell Runspaces"
  },
  "docs/powershell/remoteexecution.html": {
    "href": "docs/powershell/remoteexecution.html",
    "title": "Remote Execution | Crusader Two One",
    "keywords": "Remote Execution"
  },
  "docs/powershell/scripts.html": {
    "href": "docs/powershell/scripts.html",
    "title": "Scripts | Crusader Two One",
    "keywords": "Scripts"
  },
  "docs/powershell/security.html": {
    "href": "docs/powershell/security.html",
    "title": "Security | Crusader Two One",
    "keywords": "Security"
  },
  "docs/powershell/tipsandtricks.html": {
    "href": "docs/powershell/tipsandtricks.html",
    "title": "PowerShell Tips and Tricks | Crusader Two One",
    "keywords": "PowerShell Tips and Tricks The following is a list of tips and tricks that I've used to make the use of PowerShell better in certain situations. Setting Default Parameter Values Use the $PSDefaultParameterValues preference variable to set custom default values for cmdlets and advanced functions that you frequently use. The parameters and the default values are stored as a hash table. This feature is useful when you must specify the same parameter value nearly every time you use a cmdlet or when a particular parameter value is difficult to remember, such as an certificate thumbprint or Azure Subscription GUID. Set a parameter default value: $PSDefaultParameterValues=@{“<CmdletName>:<ParameterName>”=”<DefaultValue>”} Set several parameter default values: $PSDefaultParameterValues=@{ “<CmdletName>:<ParameterName1>”=”<DefaultValue>” “<CmdletName>:<ParameterName2>”=”<DefaultValue>” “<CmdletName>:<ParameterName3>”=”<DefaultValue>” “<CmdletName>:<ParameterName4>”=”<DefaultValue>” } Set a parameter default value based on conditions using a script block: $PSDefaultParameterValues=@{“<CmdletName>:<ParameterName>”={<ScriptBlock>}} Use the Add() method to add preferences to an existing hash table. $PSDefaultParameterValues.Add({“<CmdletName>:<ParameterName>”,”<DefaultValue>”}) Use the Remove() method to remove preferences from an existing hash table. $PSDefaultParameterValues.Remove(“<CmdletName>:<ParameterName>”) Use the Clear() method to remove all of the preferences from the hash table. $PSDefaultParameterValues.Clear() Example: Setting Default Parameters for Connect-Exchange Online: $PSDefaultParameterValues=@{ \"Connect-ExchangeOnline:UserPrincipalName\"=\"username@domainname.com\" \"Connect-ExchangeOnline:ShowBanner\"=$false \"Connect-ExchangeOnline:ShowProgress\"=$false } about_Parameters_Default_Values The $PSDefaultParameterValues preference variable lets you specify custom default values for any cmdlet or advanced function. Cmdlets and advanced functions use the custom default value unless you specify another value in the command. The authors of cmdlets and advanced functions set standard default values for their parameters. Typically, the standard default values are useful, but they might not be appropriate for all environments. This feature is especially useful when you must specify the same alternate parameter value nearly every time you use the command or when a particular parameter value is difficult to remember, such as an email server name or project GUID. If the desired default value varies predictably, you can specify a script block that provides different default values for a parameter under different conditions. $PSDefaultParameterValues=@{\"CmdletName:ParameterName\"=\"DefaultValue\"} $PSDefaultParameterValues=@{ \"CmdletName:ParameterName\"={{ScriptBlock}} } $PSDefaultParameterValues[\"Disabled\"]=$True | $False PowerShell Paths When Using Folder Redirection Group Policy is configuring folder redirection for several profile directories, including \"Documents\" where the default $PSModulePath and $Profile is located. There has been performance issues when using PowerShell remotely over VPN as it takes PowerShell a while to search $PSModulePath to autoload modules. The following PowerShell code seemed to work to change the directory that $PSModulePath points to and improved performance significantly. Setting the $Profile path to local is also included. This is not really polished or significantly tested. Your mileage may vary. # Update Profile Path $env:PSModulePath = ($env:PSModulePath).replace(\"\\\\host.domain.com\\Home\\UserName\\Documents\\PowerShell\\Modules\",\"C:\\Users\\UserName\\Documents\\PowerShell\\Modules\") $ProfilePath = $profile.CurrentUserCurrentHost if ($ProfilePath -like \"\\\\*\") { Write-Output \"ProfilePath is set to $ProfilePath. We will update this to your local profile\" $Cmd = \"& New-ItemProperty 'HKCU:\\SOFTWARE\\Microsoft\\Windows\\CurrentVersion\\Explorer\\User Shell Folders' Personal -Value '%USERPROFILE%\\Documents' -Type ExpandString -Force\" $p = Get-Process -Id $PID if ($p.processname -eq \"pwsh\") { pwsh -noprofile -command $Cmd } else { powershell -noprofile -command $Cmd } Write-Output (\"Restart {0} to continue\" -f $p.processname) }"
  },
  "docs/powershell/variables.html": {
    "href": "docs/powershell/variables.html",
    "title": "Variables | Crusader Two One",
    "keywords": "Variables"
  },
  "docs/sql/index.html": {
    "href": "docs/sql/index.html",
    "title": "SQL | Crusader Two One",
    "keywords": "SQL A place to save the SQL queries that I constantly have to Google. SELECT Statements SELECT * FROM [dbo].[table] WHERE (column = 'value1') AND (Column = 'value2') SELECT DISTINCT [column] FROM [dbo].[table] SELECT column1, COUNT(column2) FROM [dbo].[table] GROUP BY email HAVING ( COUNT(email) > 1 ) DECLARE @Temp TABLE (NAME varchar(20)) INSERT INTO @Temp (NAME) SELECT accountName --, COUNT(AccountName) AS Count FROM [StagingDirectory].[dbo].[Identities] GROUP BY accountName HAVING ( COUNT(accountName) > 1 ) SELECT [accountName] ,[lastName] ,[firstName] ,[initials] ,[employeeID] ,[employeeStatus] ,[employeeType] ,[employeeNumber] FROM @Temp Temp JOIN Identities ON Temp.name=Identities.accountname ORDER BY accountName UPDATE Statements UPDATE [dbo].[table] SET column='value' WHERE column='value'; UPDATE [dbo].[table] SET Column = REPLACE(Column,'xx','XX') INSERT Statements INSERT INTO [dbo].[table] (column1,column2,column3) VALUES ('value1','value2','value3'); DELETE Statements DELETE FROM [dbo].[table] WHERE column = 'value' MERGE Statements BEGIN TRAN; MERGE Target AS T USING Source AS S ON (T.EmployeeID = S.EmployeeID) WHEN NOT MATCHED BY TARGET AND S.EmployeeName LIKE 'S%' THEN INSERT(EmployeeID, EmployeeName) VALUES(S.EmployeeID, S.EmployeeName) WHEN MATCHED THEN UPDATE SET T.EmployeeName = S.EmployeeName WHEN NOT MATCHED BY SOURCE AND T.EmployeeName LIKE 'S%' THEN DELETE OUTPUT $action, inserted.*, deleted.*; ROLLBACK TRAN; GO Copy Table Data INSERT INTO dbo.Table2 SELECT * FROM dob.Table1; List Columns in a Table SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'TableName' SELECT COLUMN_NAME + ' ' + DATA_TYPE + '(' + CAST(CHARACTER_MAXIMUM_LENGTH AS varchar) + ')' AS Columns FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'TableName'"
  },
  "docs/sql/sqlqueries.html": {
    "href": "docs/sql/sqlqueries.html",
    "title": "SQL | Crusader Two One",
    "keywords": "SQL A place to save the SQL queries that I constantly have to Google. SELECT Statements SELECT * FROM [dbo].[table] WHERE (column = 'value1') AND (Column = 'value2') SELECT DISTINCT [column] FROM [dbo].[table] SELECT column1, COUNT(column2) FROM [dbo].[table] GROUP BY email HAVING ( COUNT(email) > 1 ) DECLARE @Temp TABLE (NAME varchar(20)) INSERT INTO @Temp (NAME) SELECT accountName --, COUNT(AccountName) AS Count FROM [StagingDirectory].[dbo].[Identities] GROUP BY accountName HAVING ( COUNT(accountName) > 1 ) SELECT [accountName] ,[lastName] ,[firstName] ,[initials] ,[employeeID] ,[employeeStatus] ,[employeeType] ,[employeeNumber] FROM @Temp Temp JOIN Identities ON Temp.name=Identities.accountname ORDER BY accountName UPDATE Statements UPDATE [dbo].[table] SET column='value' WHERE column='value'; UPDATE [dbo].[table] SET Column = REPLACE(Column,'xx','XX') INSERT Statements INSERT INTO [dbo].[table] (column1,column2,column3) VALUES ('value1','value2','value3'); DELETE Statements DELETE FROM [dbo].[table] WHERE column = 'value' MERGE Statements BEGIN TRAN; MERGE Target AS T USING Source AS S ON (T.EmployeeID = S.EmployeeID) WHEN NOT MATCHED BY TARGET AND S.EmployeeName LIKE 'S%' THEN INSERT(EmployeeID, EmployeeName) VALUES(S.EmployeeID, S.EmployeeName) WHEN MATCHED THEN UPDATE SET T.EmployeeName = S.EmployeeName WHEN NOT MATCHED BY SOURCE AND T.EmployeeName LIKE 'S%' THEN DELETE OUTPUT $action, inserted.*, deleted.*; ROLLBACK TRAN; GO Copy Table Data INSERT INTO dbo.Table2 SELECT * FROM dob.Table1; List Columns in a Table SELECT COLUMN_NAME, DATA_TYPE, CHARACTER_MAXIMUM_LENGTH FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'TableName' SELECT COLUMN_NAME + ' ' + DATA_TYPE + '(' + CAST(CHARACTER_MAXIMUM_LENGTH AS varchar) + ')' AS Columns FROM INFORMATION_SCHEMA.COLUMNS WHERE TABLE_NAME = 'TableName'"
  },
  "docs/ssh/SSHConfig.html": {
    "href": "docs/ssh/SSHConfig.html",
    "title": "SSH Configuration | Crusader Two One",
    "keywords": "SSH Configuration Server Configuration Execute Graphical Applications Remotely Enabling X11 Forwarding and Agent Forwarding will allow a user to execute a graphical application on the remote host. ForwardAgent yes ForwardX11 yes Client Configuration SSH Configuration File"
  },
  "docs/ssh/SSHForwarding.html": {
    "href": "docs/ssh/SSHForwarding.html",
    "title": "Port Forwarding | Crusader Two One",
    "keywords": "Port Forwarding SSH can be used to create secure tunnels for access to applications and services. Local Forwarding Local forwarding is used to forward a port from the client host to a remote host. The user creates a local port on the client host which listens for connections. SSH then tunnels that traffic to the remote host. Local forwarding is used for: Bypassing a firewall that prevents a protocol or to bypass web content filtering Tunnelling sessions or copying files to a remote host through a jump server or bastion host Remote access to an internal host or service from an external host Connecting to a private resource over a public network Local port forwarding is configured using the -L option: ssh -L 80:host.local-domain.com:80 host.remote-domain.com This example opens a connection to the 'host.remote-domain.com' bastion host, and forwards all connections to port 80 on the local machine, 'host.local-domain.com' to port 80 on 'host.remote-domain.com'. By default, anyone (even on different machines) can connect to the specified port on the SSH client machine. However, this can be restricted to programs on the same host by supplying a bind address: ssh -L 127.0.0.1:80:host.local-domain.com:80 host.remote-domain.com The 'LocalForward' option can be used to configure forwarding without having to specify it on command line. Remote Forwarding Remote forwading is similar to local forwarding except that is initiated from the remote host. Remote SSH port forwarding is specified by using the -R option. For example: ssh -R 8080:localhost:80 host.domain.com This example would allow someone remote access to an private service, such as a web server. Remote forwading could be performed by an employee working from home or by an attacker (AKA 'Shoveling Shell') who has established persistant access to the private environment. =====> This needs to be rewritten By default, OpenSSH only allows connecting to remote forwarded ports from the server host. However, the GatewayPorts option in the server configuration file sshd_config can be used to control this. The following alternatives are possible: GatewayPorts no This prevents connecting to forwarded ports from outside the server computer. GatewayPorts yes This allows anyone to connect to the forwarded ports. If the server is on the public Internet, anyone on the Internet can connect to the port. GatewayPorts clientspecified This means that the client can specify an IP address from which connections to the port are allowed. The syntax for this is: ssh -R 52.194.1.73:8080:localhost:80 host147.aws.example.com In this example, only connections from the IP address 52.194.1.73 to port 8080 are allowed. OpenSSH also allows the forwarded remote port to specified as 0. In this case, the server will dynamically allocate a port and report it to the client. When used with the -O forward option, the client will print the allocated port number to standard output."
  },
  "docs/ssh/SSHKeys.html": {
    "href": "docs/ssh/SSHKeys.html",
    "title": "SSH Keys | Crusader Two One",
    "keywords": "SSH Keys SSH Keys are asymetric cryprographic keys, or key pairs, that are used for authorization and authentication. A key pair consists of a private key (Identification key) and a public key (Authorization key). The owner of a key pair is authorized access to a resource by installing that user's public key (Authorization) on that resource. The user then uses the private key (Identity) to authenticate to that resource. The private key is protected by a passowrd or passphrase that only the owner knows. A users private key's are to be protected the same as passwords. SSH keys may be used to interactivly access a host or service or can be used to privide authorization and authentication to automated processes. This is typically accomplised by creating a key pair without a password. Host Keys Host keys represent a server's identity and are used by the client to authenticate that server's identity. The first time a client accesses a server, the client will prompt the user, displaying a hash of the server's host key and asking the user to expliicitly accept it. $ ssh -t git@ssh.github.com The authenticity of host 'ssh.github.com (140.82.114.36)' can't be established. ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU. Are you sure you want to continue connecting (yes/no/[fingerprint])? If the host key stored in 'known_hosts' does not match the one presented to the client by the server the client will promp the usuer, asking if the user wants to continue. @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ @ WARNING: REMOTE HOST IDENTIFICATION HAS CHANGED! @ @@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@@ IT IS POSSIBLE THAT SOMEONE IS DOING SOMETHING NASTY! Someone could be eavesdropping on you right now (man-in-the-middle attack)! It is also possible that a host key has just been changed. The fingerprint for the RSA key sent by the remote host is 6e:45:f9:a8:af:38:3d:a1:a5:c7:76:1d:02:f8:77:00. Please contact your system administrator. Add correct host key in /home/hostname /.ssh/known_hosts to get rid of this message. Offending RSA key in /var/lib/sss/pubconf/known_hosts:4 RSA host key for pong has changed and you have requested strict checking. Host key verification failed. Change Host Key Follow these steps to regenerate OpenSSH Host Keys Delete old ssh host keys rm /etc/ssh/ssh_host_* Reconfigure OpenSSH Server dpkg-reconfigure openssh-server Update ssh client(s) ~/.ssh/known_hosts files with the new hash SSH Key pair Creation Enter the following command to generate a new SSH key pair ssh-keygen -t ed25519 -C \"alias@example.com\" or the following for legacy systems ssh-keygen -t ed25519 -C \"your_email@example.com\""
  },
  "docs/ssh/SSHUse.html": {
    "href": "docs/ssh/SSHUse.html",
    "title": "SSH Connect | Crusader Two One",
    "keywords": "SSH Connect Authentiction The authenticity of host 'ssh.github.com (140.82.113.35)' can't be established. ED25519 key fingerprint is SHA256:+DiY3wvvV6TuJJhbpZisF/zLDA0zPMSvHdkr4UvCOqU. This key is not known by any other names Are you sure you want to continue connecting (yes/no/[fingerprint])? yes Warning: Permanently added 'ssh.github.com' (ED25519) to the list of known hosts. Authenticate with a Specific Key A specific key can be specified in the SSH command. ssh -i ~/.ssh/id_rsa_host username@host.domain.com Compare Public Key Fingerprint If you are having trouble logging into a host or a service you can confirm that the fingerprint of your public key matches what was uploaded. ssh-keygen -l -E md5 -f ~/.ssh/id_rsa_ado.pub Test Authentication The following command will test authentiction to a specific host. ssh -T git@ssh.github.com In the case of source control services, you may get the following error. This is simply because the service is not intended for shell access and is completely normal. remote: Shell access is not supported."
  },
  "docs/ssh/SecureFileCopy.html": {
    "href": "docs/ssh/SecureFileCopy.html",
    "title": "Secure File Copy - SCP | Crusader Two One",
    "keywords": "Secure File Copy - SCP SCP uses the SSH protocol to securly copy files between systems. SCP is often included as part of the SSH client application. Copy a file The SCP command for copying a file from a local path to a remote host scp file host:path For example: scp script.sh admin@host.domain.com:/home/admin/ The SCP command for copying a file from the remote host to a local path. scp host:file path For example: scp admin@host.domain.com:/home/admin/script.sh script.sh"
  },
  "docs/ssh/index.html": {
    "href": "docs/ssh/index.html",
    "title": "Secure Shell - SSH | Crusader Two One",
    "keywords": "Secure Shell - SSH Secure Shell Protocol, or SSH, is a remote administration protocol that allows users to securly access a remote system for tasks such as adminstration and file copy. SSH was created to replace insecure administrative protocols like telnet. SSH uses cryptographic techniques to autheticate users and ensure that communications between hosts are encrypted. User authentication in SSH can be performed using username and password or cryptographic key pairs. Uses for SSH SSH is primarily known for providing remote termial access to a host for administration. SSH can also be used to create seocure tunnels and to transfer files."
  },
  "docs/terraform/index.html": {
    "href": "docs/terraform/index.html",
    "title": "Terraform | Crusader Two One",
    "keywords": "Terraform"
  },
  "docs/terraform/proxmox.html": {
    "href": "docs/terraform/proxmox.html",
    "title": "Terraform Proxmox | Crusader Two One",
    "keywords": "Terraform Proxmox"
  },
  "docs/unifi/802.1x.html": {
    "href": "docs/unifi/802.1x.html",
    "title": "Unifi Dream Machine MAC Authentication | Crusader Two One",
    "keywords": "Unifi Dream Machine MAC Authentication Settings -> Networks Under Global Switch Settings click checkbox to enable 802.1x Control Select RADIUS Profile (Default) Select Fallback VLAN Settings -> WiFi Select WiFi network Click checkbox to enable RADIUS MAC Authentication Select MAC Address Format (aa:bb:cc:dd:ee:ff) Select Security Protocol (WPA-Enterprise) Settings -> Profile -> RADIUS Select Default profile Select checkboxes for Wired and Wireless Networks Click Create New RADIUS User Enter the following information: Username - Enter MAC address (Use selected format) Password - Enter MAC address (Use selected format) VLAN ID - Enter desired VLAN Tunnel Type - 13 – Virtual LANs (VLAN) Tunnel Medium Type – 6 – 802 (includes all 802 media plus Ethernet canonical format) Click Create User Enter the following information: Username - Enter User ID for the user Password - Enter a password for the user VLAN ID - Enter 0 Tunnel Type – Leave as None Tunnel Medium Type – Leave as None Configure New Host in RADIUS Settings -> Profile -> RADIUS Select Default profile Click Create New RADIUS User Enter the following information: Username - Enter MAC address (Use selected format) Password - Enter MAC address (Use selected format) VLAN ID - Enter desired VLAN Tunnel Type - 13 – Virtual LANs (VLAN) Tunnel Medium Type – 6 – 802 (includes all 802 media plus Ethernet canonical format) Click Create User"
  },
  "docs/unifi/index.html": {
    "href": "docs/unifi/index.html",
    "title": "Unifi Networking | Crusader Two One",
    "keywords": "Unifi Networking"
  },
  "docs/unifi/networking.html": {
    "href": "docs/unifi/networking.html",
    "title": "Networks | Crusader Two One",
    "keywords": "Networks VLANS/Subnets The following tables outline the separate subnets/VLANS used for each site. Fall River Name VLAN Subnet Description Default 1 192.168.0.0/24 Native VLAN Trusted 101 192.168.1.0/24 Trusted hosts Secure 103 192.168.3.0/24 \"Work\" hosts Guest 104 192.168.4.0/24 Guest devices VPN 105 192.168.5.0/24 Remote devices Device 106 192.168.6.0/24 IoT Devices Cameras 107 192.168.7.0/24 Security Cameras Gameing 108 192.168.8.0/24 Gameing devices Servers 127 192.168.127.0/24 Server devices Oconto Name VLAN Subnet Description Default 1 192.168.128.0/24 Native VLAN Trusted 1129 192.168.129.0/24 Trusted hosts Secure 1130 192.168.130.0/24 \"Work\" hosts Guest 1131 192.168.131.0/24 Guest devices VPN 1132 192.168.132.0/24 Remote devices Device 1133 192.168.133.0/24 IoT Devices Cameras 1134 192.168.134.0/24 Security Cameras Gameing 1135 192.168.135.0/24 Gameing devices Servers 1136 192.168.254.0/24 Server devices Firewall Rules Guest Network"
  },
  "docs/vscode/configure.html": {
    "href": "docs/vscode/configure.html",
    "title": "Visual Studio Code Configuration | Crusader Two One",
    "keywords": "Visual Studio Code Configuration Overview The overall intent of this document is to configure VS Code for use as a PowerShell development tool. The configuration will focus on PowerShell and other technologies that may be used in conjunction with PowerShell. Install Extensions VS Code is designed to be very extensible. THere are a few Extensions that we will install to make it possible to develop PowerShell code. PowerShell Extension GitHub Copilot GitHub Copilot is a subscription service that provides the capability to leverage AI to assist in writing code. Configure Extension Preferences PowerShell Extension Settings In this section we will be focusing on primarily configuring the PowerShell extension. Name Setting Click the Settings Sproket in the lower left-hand corner and select \"Settings\" from the menu Select \"User\" at the top and scroll down and expand \"Extensions\" in the left pane Click on \"PowerShell\" under \"Extensions\" and then update the following settings as needed: Code Folding – Enable Add Whitespace Around Pipe (|) – Enable Auto Correct Aliases – Enable Avoid Semicolons As Line Terminators - Enable Open Brace On Same Line – Disable Trim Whitespace Around Pipe – Enable Use Correct Casing – Enable Configure Code Snippets VS Code provides the ability to create custom code snippets. This way, if there is a particular function that you used regularly, you can quickly and easily enter it with only a few key strokes. This is from the MS docs Snippets in Visual Studio Code You can easily define your own snippets without any extension. To create or edit your own snippets, select Configure User Snippets under File > Preferences, and then select the language (by language identifier) for which the snippets should appear, or the New Global Snippets file option if they should appear for all languages. VS Code manages the creation and refreshing of the underlying snippets file(s) for you. Snippets files are written in JSON, support C-style comments, and can define an unlimited number of snippets. Snippets support most TextMate syntax for dynamic behavior, intelligently format whitespace based on the insertion context, and allow easy multiline editing. Below is an example of a for loop snippet for JavaScript: // in file 'Code/User/snippets/javascript.json' { \"For Loop\": { \"prefix\": [\"for\", \"for-const\"], \"body\": [\"for (const ${2:element} of ${1:array}) {\", \"\\t$0\", \"}\"], \"description\": \"A for loop.\" } } In the example above: \"For Loop\" is the snippet name. It is displayed via IntelliSense if no description is provided. prefix defines one or more trigger words that display the snippet in IntelliSense. Substring matching is performed on prefixes, so in this case, \"fc\" could match \"for-const\". body is one or more lines of content, which will be joined as multiple lines upon insertion. Newlines and embedded tabs will be formatted according to the context in which the snippet is inserted. description is an optional description of the snippet displayed by IntelliSense. Additionally, the body of the example above has three placeholders (listed in order of traversal): ${1:array}, ${2:element}, and $0. You can quickly jump to the next placeholder with Tab, at which point you may edit the placeholder or jump to the next one. The string after the colon : (if any) is the default text, for example element in ${2:element}. Placeholder traversal order is ascending by number, starting from one; zero is an optional special case that always comes last, and exits snippet mode with the cursor at the specified position."
  },
  "docs/vscode/index.html": {
    "href": "docs/vscode/index.html",
    "title": "Visual Studio Code\\ | Crusader Two One",
    "keywords": "Visual Studio Code\\"
  },
  "docs/vscode/install.html": {
    "href": "docs/vscode/install.html",
    "title": "Installation | Crusader Two One",
    "keywords": "Installation The following steps will install and configure VS Code with the primary intended purpose of working with PowerShell. Download and Install VS Code and Git for Windows winget install Microsoft.VisualStudioCode --override '/SILENT /mergetasks=\"!runcode,addcontextmenufiles,addcontextmenufolders\"' (How to use winget to install VSCode with custom options? · microsoft/winget-cli · Discussion #1798 · GitHub) winget install --id Git.Git -e --source winget"
  },
  "docs/vscode/tipaandtricks.html": {
    "href": "docs/vscode/tipaandtricks.html",
    "title": "| Crusader Two One",
    "keywords": ""
  },
  "index.html": {
    "href": "index.html",
    "title": "Knowledge Base | Crusader Two One",
    "keywords": "Knowledge Base This serves as my personal knowledge base. An online notebook of sorts for information I would like to store for later use. Topics PowerShell Docker Secure Shell Git SQL Unifi Networking Home Lab Home Assistant Terraform Ansible"
  }
}